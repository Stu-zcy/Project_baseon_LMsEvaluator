general:
  random_seed: 0
  use_gpu: True

LM_config:
  #  model: bert_base_chinese
  model: bert_base_uncased_english

task_config:
  task: TaskForSingleSentenceClassification
  dataset: imdb
  dataset_type: ".txt"
  split_sep: "_!_"
  epochs: 1
#  task: TaskForSQuADQuestionAnswering
#  dataset: SQuAD
#  dataset_type: ".json"

attack_list:
  - attack_args:
      attack: True
      attack_type: AdvAttack
      attack_recipe: TextFoolerJin2019
      use_local_model: True
      use_local_tokenizer: True
      use_local_dataset: True
      model_name_or_path: "LMs/bert_base_uncased_english"
      tokenizer_name_or_path: "LMs/bert_base_uncased_english"
      dataset_name_or_path: "datasets/imdb/train.txt"
      attack_nums: 2
      display_full_info: True
  - attack_args:
      attack: False
      attack_type: SWAT
      seed: 42
      attack_batch: 2
      attack_nums: 1
      distance_func: l2
      population_size: 300
      tournsize: 5
      crossover_rate: 0.9
      mutation_rate: 0.1
      max_generations: 2 #100
      halloffame_size: 30
      use_local_model: True
      use_local_tokenizer: True
      model_name_or_path: "LMs/bert_base_uncased_english"
      tokenizer_name_or_path: "LMs/bert_base_uncased_english"
      dataset_name_or_path: "cola"
      display_full_info: True
  - attack_args:
      attack: False
      attack_type: BackDoorAttack
      use_local_model: True
      model: "bert"
      model_name_or_path: "LMs/bert_base_uncased_english"
      poison_dataset: "sst-2"
      target_dataset: "sst-2"
      poisoner:
        "name": "badnets"
      train:
        "name": "base"
        "batch_size": 4
        "epochs": 1
      defender: "None"
      sample_metrics: ['ppl', 'use']
      display_full_info: True
  - attack_args:
      attack: False
      attack_type: PoisoningAttack
      poisoning_rate: 0.1
      epochs: 10
      display_full_info: True

#attack_args:
#  attack: True
#  attack_type: AdvAttack
#  attack_recipe: TextFoolerJin2019
#  use_local_model: True
#  use_local_tokenizer: True
#  use_local_dataset: True
#  model_name_or_path: "LMs/bert_base_chinese"
#  tokenizer_name_or_path: "LMs/bert_base_chinese"
#  dataset_name_or_path: "data/imdb/test.txt"
#  attack_nums: 2

## GIAforNLP攻击配置文件示例
#attack_args:
#  attack: True                        # boolean: 表示是否开启攻击
#  attack_type: GIAforNLP               # str: 攻击方法,'GIAforNLP'代表梯度反转攻击
#  attack_data: None                    # str: 攻击方法所使用的数据集路径
#  optimizer: Adam                     # str: 攻击方法所使用的优化器
#  attack_batch: 2                      # int: 一次攻击中数据的Batch size
#  attack_nums: 1                       # int: 攻击次数
#  distance_func: l2                    # str: 攻击方法中的距离函数, 'l2' or 'cos'
#  attack_lr: 0.01                      # float: 攻击方法中的学习率
#  attack_iters: 10                     # int: 一次攻击中的迭代轮次

## SWAT攻击配置文件示例
#attack_args:
#  attack: True                        # boolean: 表示是否开启攻击
#  attack_type: SWAT                    # str: 攻击方法,'GIAforNLP'代表梯度反转攻击
#  seed: 42
#  attack_batch: 2                      # int: 一次攻击中数据的Batch size
#  attack_nums: 1                       # int: 攻击次数
#  distance_func: l2                    # str: 攻击方法中的距离函数, 'l2' or 'cos'
#  population_size: 300
#  tournsize: 10
#  crossover_rate: 0.9
#  mutation_rate: 0.1
#  max_generations: 100
#  halloffame_size: 30
#  use_local_model: True                 # boolean: 是否使用本地model
#  use_local_tokenizer: True             # boolean: 是否使用本地tokenizer
#  model_name_or_path: "LMs/bert_base_uncased_english"      # modelNameOrPath: str, 攻击所用model在Huggingface的名称或本地路径
#  tokenizer_name_or_path: "LMs/bert_base_uncased_english"  # tokenizerNameOrPath: str, 攻击所用tokenizer在Huggingface的名称或本地路径
#  dataset_name_or_path: "cola"           # datasetNameOrPath: str, 攻击所用dataset在Huggingface的名称或本地路径

## 对抗性文本攻击配置文件示例
#attack_args:
#  attack: True                    # boolean: 是否开启攻击
#  attack_type: AdvAttack           # attackType: str, 攻击方法, ‘AdvAttack’代表对抗性文本攻击
#  attack_recipe: TextFoolerJin2019     # str: 具体攻击策略
#  use_local_model: True                 # boolean: 是否使用本地model
#  use_local_tokenizer: True             # boolean: 是否使用本地tokenizer
#  use_local_dataset: True               # boolean: 是否使用本地dataset
#  model_name_or_path: "LMs/bert_base_uncased_english"      # modelNameOrPath: str, 攻击所用model在Huggingface的名称或本地路径
#  tokenizer_name_or_path: "LMs/bert_base_uncased_english"  # tokenizerNameOrPath: str, 攻击所用tokenizer在Huggingface的名称或本地路径
#  dataset_name_or_path: "data/imdb/test.txt"       # datasetNameOrPath: str, 攻击所用dataset在Huggingface的名称或本地路径
#  attack_nums: 2                   # int: 攻击次数

output:
  base_path: "output"
  model_output: "modelOutput"
  evaluation_result: "evaluationResult"

#下游任务参考配置(更加具体的配置可以在utlis/model_config里进行修改)，下面是一些配置示例：
#TaskForSingleSentenceClassification:
#  model: bert_base_chinese
#  dataset: SingleSentenceClassification
#  dataset: imdb
#  dataset: GLUE/cola
#  dataset: GLUE/sst2
#  dataset_type: ".txt"
#
#TaskForSQuADQuestionAnswering:
#  model: bert_base_uncased_english
#  dataset: SQuAD
#  dataset_type: ".json"
#
#TaskForChineseNER:
#  model: bert_base_chinese
#  dataset: ChineseNER
#  dataset_type: ".txt"
#  split_sep: " "
#
#TaskForMultipleChoice:
#  model: bert_base_uncased_english
#  dataset: MultipleChoice
#  dataset_type: ".csv"
#
#TaskForPairSentenceClassification:
#  model: bert_base_uncased_english
#  dataset: GLUE/mnli
#  dataset: PairSentenceClassification
#  dataset_type: ".txt"
#  split_sep: "_!_"
#
#TaskForPretraining:
#  model: bert_base_chinese
#  dataset: SongCi
#  dataset_type: ".txt"
#
#  model: bert_base_uncased_english
#  dataset: WikiText
#  dataset_type: ".tokens"
