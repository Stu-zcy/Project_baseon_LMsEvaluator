LM_config:
  local_model: true
  model: bert_base_uncased
attack_list:
# - attack_args:
#     attack: true
#     attack_nums: 3
#     attack_recipe: BAEGarg2019
#     attack_type: AdvAttack
#     dataset_name_or_path: datasets/imdb/train.txt
#     defender:
#       gradient_accumulation_steps: 4
#       learning_rate: 5.0e-05
#       log_to_tb: false
#       num_clean_epochs: 0
#       num_epochs: 1
#       num_train_adv_examples: 100
#       per_device_train_batch_size: 4
#     display_full_info: true
#     model_name_or_path: LMs/bert_base_uncased
#     tokenizer_name_or_path: LMs/bert_base_uncased
#     use_local_dataset: true
#     use_local_model: true
#     use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: BERTAttackLi2020
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: GeneticAlgorithmAlzantot2018
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: FasterGeneticAlgorithmJia2019
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: DeepWordBugGao2018
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: HotFlipEbrahimi2017
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: InputReductionFeng2018
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: Kuleshov2017
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: MorpheusTan2020
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: Seq2SickCheng2018BlackBox
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: TextBuggerLi2018
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: TextFoolerJin2019
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: PWWSRen2019
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: IGAWang2019
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: Pruthi2019
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: PSOZang2020
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: CheckList2020
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: CLARE2020
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: FrenchRecipe
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: SpanishRecipe
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
- attack_args:
    attack: true
    attack_nums: 2
    attack_recipe: ChineseRecipe
    attack_type: AdvAttack
    dataset_name_or_path: datasets/imdb/train.txt
    defender:
      gradient_accumulation_steps: 4
      learning_rate: 5.0e-05
      log_to_tb: false
      num_clean_epochs: 0
      num_epochs: 1
      num_train_adv_examples: 10
      per_device_train_batch_size: 4
    display_full_info: true
    model_name_or_path: LMs/bert_base_uncased
    tokenizer_name_or_path: LMs/bert_base_uncased
    use_local_dataset: true
    use_local_model: true
    use_local_tokenizer: true
general:
  log_file_name: Zhao_single_1755740769
  logs_save_dir: ./logs
  random_seed: 42
  use_gpu: true
task_config:
  dataset: GLUE/cola
  local_dataset: true
  normal_training: true
  save_path: ./cache/model_output
  task: TaskForSingleSentenceClassification
  train_config:
    logging_dir: ./logs
    logging_steps: 1000
    num_train_epochs: 3
    output_dir: ./cache
    per_device_eval_batch_size: 64
    per_device_train_batch_size: 16
    report_to: none
    run_name: my_experiment
    warmup_steps: 1000
    weight_decay: 0.01
