{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T03:47:52.087628Z",
     "start_time": "2025-06-23T03:26:22.625038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:22] - INFO: 成功导入BERT配置文件 /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased/config.json\n",
      "[2025-06-23 11:26:22] - INFO:  ### 将当前配置打印到日志文件中 \n",
      "[2025-06-23 11:26:22] - INFO: ###  project_dir = /Volumes/T7 Shield/Project/LMsEvaluator\n",
      "[2025-06-23 11:26:22] - INFO: ###  dataset_dir = /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb\n",
      "[2025-06-23 11:26:22] - INFO: ###  pretrained_model_dir = /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased\n",
      "[2025-06-23 11:26:22] - INFO: ###  vocab_path = /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased/vocab.txt\n",
      "[2025-06-23 11:26:22] - INFO: ###  device = mps\n",
      "[2025-06-23 11:26:22] - INFO: ###  train_file_path = /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb/train.txt\n",
      "[2025-06-23 11:26:22] - INFO: ###  val_file_path = /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb/val.txt\n",
      "[2025-06-23 11:26:22] - INFO: ###  test_file_path = /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb/test.txt\n",
      "[2025-06-23 11:26:22] - INFO: ###  model_load_dir = /Volumes/T7 Shield/Project/LMsEvaluator/cache/modelLoad\n",
      "[2025-06-23 11:26:22] - INFO: ###  model_save_dir = /Volumes/T7 Shield/Project/LMsEvaluator/cache/modelOutput\n",
      "[2025-06-23 11:26:22] - INFO: ###  checkpoint_dir = /Volumes/T7 Shield/Project/LMsEvaluator/checkpoints\n",
      "[2025-06-23 11:26:22] - INFO: ###  logs_save_dir = /Volumes/T7 Shield/Project/LMsEvaluator/logs\n",
      "[2025-06-23 11:26:22] - INFO: ###  config_parser = {'general': {'random_seed': 42, 'use_gpu': True}, 'LM_config': {'model': 'bert_base_uncased'}, 'task_config': {'task': 'TaskForSingleSentenceClassification', 'dataset': 'imdb', 'num_labels': 2, 'dataset_type': '.txt', 'split_sep': '_!_', 'epochs': 1}, 'attack_list': [{'attack_args': {'attack': False, 'attack_type': 'lamp', 'attack_config': {'dataset': 'sst2', 'split': 'test', 'loss': 'cos'}}}, {'attack_args': {'attack': False, 'attack_type': 'RLMI', 'dataset_name': 'emotion', 'model_name': 'tinybert4', 'seed': 42, 'ppo_config': {'mini_batch_size': 16, 'batch_size': 16, 'log_with': 'None', 'learning_rate': '1e-5'}, 'seq_length': 20, 'target_label': 0, 'max_iterations': 2000, 'min_input_length': 2, 'max_input_length': 5, 'num_generation': 1000}}, {'attack_args': {'attack': True, 'attack_type': 'AdvAttack', 'attack_recipe': 'TextFoolerJin2019', 'use_local_model': True, 'use_local_tokenizer': True, 'use_local_dataset': True, 'model_name_or_path': 'LMs/bert_base_uncased', 'tokenizer_name_or_path': 'LMs/bert_base_uncased', 'dataset_name_or_path': 'datasets/imdb/train.txt', 'attack_nums': 20, 'display_full_info': True}}, {'attack_args': {'attack': False, 'attack_type': 'ModelStealingAttack', 'method': 'RS', 'query_num': 320, 'run_seed_arr': [56], 'pool_data_type': 'whole', 'pool_data_source': 'wiki', 'pool_subsize': -1, 'prompt': 'None', 'epsilon': -1, 'initial_sample_method': 'random_sentence', 'initial_drk_model': 'None', 'al_sample_batch_num': -1, 'al_sample_method': 'None'}}, {'attack_args': {'attack': False, 'attack_type': 'FET', 'seed': 42, 'attack_batch': 2, 'attack_nums': 1, 'distance_func': 'l2', 'population_size': 300, 'tournsize': 5, 'crossover_rate': 0.9, 'mutation_rate': 0.1, 'max_generations': 2, 'halloffame_size': 30, 'use_local_model': True, 'use_local_tokenizer': True, 'model_name_or_path': 'LMs/bert_base_uncased', 'tokenizer_name_or_path': 'LMs/bert_base_uncased', 'dataset_name_or_path': 'cola', 'display_full_info': True}}, {'attack_args': {'attack': False, 'attack_type': 'BackdoorAttack', 'use_local_model': True, 'model': 'bert', 'model_name_or_path': 'LMs/bert_base_uncased', 'poison_dataset': 'sst-2', 'target_dataset': 'sst-2', 'poisoner': {'name': 'badnets'}, 'train': {'name': 'base', 'batch_size': 32, 'epochs': 1}, 'defender': 'None', 'sample_metrics': ['ppl', 'use'], 'display_full_info': True}}, {'attack_args': {'attack': False, 'attack_type': 'PoisoningAttack', 'poisoning_rate': 0.1, 'epochs': 10, 'display_full_info': True}}, {'attack_args': {'attack': False, 'attack_type': 'NOP', 'nop_config0': 'nop_config0', 'nop_config1': 'nop_config1'}}], 'output': {'base_path': 'output', 'model_output': 'modelOutput', 'evaluation_result': 'evaluationResult'}}\n",
      "[2025-06-23 11:26:22] - INFO: ###  log_level = 20\n",
      "[2025-06-23 11:26:22] - INFO: ###  vocab_size = 30522\n",
      "[2025-06-23 11:26:22] - INFO: ###  hidden_size = 768\n",
      "[2025-06-23 11:26:22] - INFO: ###  num_hidden_layers = 12\n",
      "[2025-06-23 11:26:22] - INFO: ###  num_attention_heads = 12\n",
      "[2025-06-23 11:26:22] - INFO: ###  intermediate_size = 3072\n",
      "[2025-06-23 11:26:22] - INFO: ###  pad_token_id = 0\n",
      "[2025-06-23 11:26:22] - INFO: ###  hidden_act = gelu\n",
      "[2025-06-23 11:26:22] - INFO: ###  hidden_dropout_prob = 0.1\n",
      "[2025-06-23 11:26:22] - INFO: ###  attention_probs_dropout_prob = 0.1\n",
      "[2025-06-23 11:26:22] - INFO: ###  max_position_embeddings = 512\n",
      "[2025-06-23 11:26:22] - INFO: ###  type_vocab_size = 2\n",
      "[2025-06-23 11:26:22] - INFO: ###  initializer_range = 0.02\n",
      "[2025-06-23 11:26:22] - INFO: ###  split_sep = _!_\n",
      "[2025-06-23 11:26:22] - INFO: ###  is_sample_shuffle = True\n",
      "[2025-06-23 11:26:22] - INFO: ###  batch_size = 1\n",
      "[2025-06-23 11:26:22] - INFO: ###  max_sen_len = None\n",
      "[2025-06-23 11:26:22] - INFO: ###  num_labels = 2\n",
      "[2025-06-23 11:26:22] - INFO: ###  epochs = 1\n",
      "[2025-06-23 11:26:22] - INFO: ###  model_val_per_epoch = 2\n",
      "[2025-06-23 11:26:22] - INFO: ###  architectures = ['BertForMaskedLM']\n",
      "[2025-06-23 11:26:22] - INFO: ###  gradient_checkpointing = False\n",
      "[2025-06-23 11:26:22] - INFO: ###  layer_norm_eps = 1e-12\n",
      "[2025-06-23 11:26:22] - INFO: ###  model_type = bert\n",
      "[2025-06-23 11:26:22] - INFO: ###  position_embedding_type = absolute\n",
      "[2025-06-23 11:26:22] - INFO: ###  transformers_version = 4.6.0.dev0\n",
      "[2025-06-23 11:26:22] - INFO: ###  use_cache = True\n",
      "[2025-06-23 11:26:22] - INFO: ###  pooler_type = first_token_transform\n",
      "[2025-06-23 11:26:22] - INFO: ## Loading Model from /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased\n",
      "[2025-06-23 11:26:25] - INFO: ## 注意，正在使用本地MyTransformer中的MyMultiHeadAttention实现，如需使用torch框架中的MultiHeadAttention模块可通过config.__dict__['use_torch_multi_head'] = True实现\n",
      "[2025-06-23 11:26:26] - INFO:  ## 索引预处理缓存文件的参数为：['max_sen_len']\n",
      "[2025-06-23 11:26:26] - INFO: 缓存文件 /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb/cache_test_max_sen_lenNone.pt 存在，直接载入缓存文件！\n",
      "[2025-06-23 11:26:30] - INFO: 数据预处理一共耗时3.601s\n",
      "[2025-06-23 11:26:30] - INFO:  ## 索引预处理缓存文件的参数为：['max_sen_len']\n",
      "[2025-06-23 11:26:30] - INFO: 缓存文件 /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb/cache_train_max_sen_lenNone.pt 存在，直接载入缓存文件！\n",
      "[2025-06-23 11:26:33] - INFO: 数据预处理一共耗时2.632s\n",
      "[2025-06-23 11:26:33] - INFO:  ## 索引预处理缓存文件的参数为：['max_sen_len']\n",
      "[2025-06-23 11:26:33] - INFO: 缓存文件 /Volumes/T7 Shield/Project/LMsEvaluator/datasets/imdb/cache_val_max_sen_lenNone.pt 存在，直接载入缓存文件！\n",
      "[2025-06-23 11:26:35] - INFO: 数据预处理一共耗时2.649s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch[0/25000]:   0%|          | 0/25000 [00:01<?, ?it/s, Avg Loss=0.800, Avg Train Acc=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:37] - INFO: Epoch: 0, Batch[0/25000], Avg Loss :0.800, Avg Train Acc: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch[0/25000]:   0%|          | 0/25000 [00:01<?, ?it/s, Avg Loss=0.800, Avg Train Acc=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:37] - INFO: Epoch: 0, Train loss: 0.000, Epoch time = 1.957s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch[0/25000]:   0%|          | 0/25000 [00:00<?, ?it/s, Avg Acc=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:37] - INFO: Accuracy on val 0.000\n",
      "[2025-06-23 11:26:37] - INFO: ## Loading Model from /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:40] - INFO: ## 注意，正在使用本地MyTransformer中的MyMultiHeadAttention实现，如需使用torch框架中的MultiHeadAttention模块可通过config.__dict__['use_torch_multi_head'] = True实现\n",
      "[2025-06-23 11:26:42] - INFO: ## 已有模型存储路径: /Volumes/T7 Shield/Project/LMsEvaluator/cache/modelOutput/task4sst_model.pt\n",
      "[2025-06-23 11:26:42] - INFO: ## 成功载入已有模型\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch[0/25000]:   0%|          | 0/25000 [00:00<?, ?it/s, Avg Acc=1.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:42] - INFO: Acc on test:1.000\n",
      "+----------+----------+\n",
      "| Results  |          |\n",
      "+----------+----------+\n",
      "| Accuracy | 100.000% |\n",
      "+----------+----------+\n",
      "[2025-06-23 11:26:42] - INFO: \n",
      "+----------+----------+\n",
      "| Results  |          |\n",
      "+----------+----------+\n",
      "| Accuracy | 100.000% |\n",
      "+----------+----------+\n",
      "[2025-06-23 11:26:42] - INFO: ==================================================\n",
      "[2025-06-23 11:26:42] - INFO: 模型正常训练结束\n",
      "[2025-06-23 11:26:42] - INFO: ==================================================\n",
      "[2025-06-23 11:26:42] - INFO: ## Loading Model from /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:26:44] - INFO: ## 注意，正在使用本地MyTransformer中的MyMultiHeadAttention实现，如需使用torch框架中的MultiHeadAttention模块可通过config.__dict__['use_torch_multi_head'] = True实现\n",
      "[2025-06-23 11:26:46] - INFO: ## 已有模型存储路径: /Volumes/T7 Shield/Project/LMsEvaluator/cache/modelOutput/task4sst_model.pt\n",
      "[2025-06-23 11:26:46] - INFO: ## 成功载入已有模型\n",
      "[2025-06-23 11:26:46] - INFO: ==================================================\n",
      "[2025-06-23 11:26:46] - INFO: 攻击模块配置检查\n",
      "[2025-06-23 11:26:46] - INFO: Checking the config of AdvAttack.\n",
      "[2025-06-23 11:26:46] - INFO: AdvAttack攻击开始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /Volumes/T7 Shield/Project/LMsEvaluator/LMs/bert_base_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to CSV at path /Volumes/T7 Shield/Project/LMsEvaluator/attack/AdvAttack/log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   5%|▌         | 1/20 [00:02<00:52,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 11:27:10] - INFO: Using /var/folders/dr/nw8_6x6j4fv59rr15xft1m940000gn/T/tfhub_modules to cache modules.\n",
      "[2025-06-23 11:27:11] - INFO: Fingerprint not found. Saved model loading will continue.\n",
      "[2025-06-23 11:27:11] - INFO: path_and_singleprint metric could not be logged. Saved model loading will continue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 1 / 5:  25%|██▌       | 5/20 [02:53<08:40, 34.70s/it]textattack: Saving checkpoint under \"checkpoints/1750649380564.ta.chkpt\" at 2025-06-23 11:29:40 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 0 / 3 / 10:  50%|█████     | 10/20 [05:27<05:27, 32.74s/it]textattack: Saving checkpoint under \"checkpoints/1750649534502.ta.chkpt\" at 2025-06-23 11:32:14 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 6 / 15:  75%|███████▌  | 15/20 [08:08<02:42, 32.59s/it]textattack: Saving checkpoint under \"checkpoints/1750649695904.ta.chkpt\" at 2025-06-23 11:34:55 after 15 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 0 / 8 / 20: 100%|██████████| 20/20 [21:04<00:00, 63.21s/it]textattack: Saving checkpoint under \"checkpoints/1750650471315.ta.chkpt\" at 2025-06-23 11:47:51 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 12 / 0 / 8 / 20: 100%|██████████| 20/20 [21:04<00:00, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 12     |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 8      |\n",
      "| Original accuracy:            | 60.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 3.66%  |\n",
      "| Average num. words per input: | 236.85 |\n",
      "| Avg num queries:              | 846.17 |\n",
      "+-------------------------------+--------+\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 12     |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 8      |\n",
      "| Original accuracy:            | 60.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "+-------------------------------+--------+\n",
      "[2025-06-23 11:47:51] - INFO: \n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 12     |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 8      |\n",
      "| Original accuracy:            | 60.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "+-------------------------------+--------+\n",
      "[2025-06-23 11:47:51] - INFO: AdvAttack攻击结束\n",
      "[2025-06-23 11:47:51] - INFO: ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "  %run main.py\n",
    "  # - attack_args:\n",
    "  #     attack: True\n",
    "  #     attack_type: AdvAttack\n",
    "  #     attack_recipe: TextFoolerJin2019\n",
    "  #     use_local_model: True\n",
    "  #     use_local_tokenizer: True\n",
    "  #     use_local_dataset: True\n",
    "  #     model_name_or_path: \"LMs/bert_base_uncased\"\n",
    "  #     tokenizer_name_or_path: \"LMs/bert_base_uncased\"\n",
    "  #     dataset_name_or_path: \"datasets/imdb/train.txt\"\n",
    "  #     attack_nums: 20\n",
    "  #     display_full_info: True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
